{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Chelsea Jaculina\n",
        "\n",
        "DATA 255 Assignment #6\n",
        "\n",
        "October 27, 2025"
      ],
      "metadata": {
        "id": "WIzw6wztjWM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 1. SETUP AND IMPORTS\n",
        "# ================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import zipfile\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "# For reproducibility\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXbUqkKahNId",
        "outputId": "f22c87ea-97f4-4146-8a6a-fc7fd56879e5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA A100-SXM4-80GB\n",
            "GPU Memory: 79.32 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 2. MOUNT GOOGLE DRIVE & EXTRACT DATA\n",
        "# ================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_zip_path = \"/content/drive/MyDrive/MSDA 2024-2026/04 Fall 2025/DATA 255 - Deep Learning/HW6/imagenet_train20a.zip\"\n",
        "val_zip_path = \"/content/drive/MyDrive/MSDA 2024-2026/04 Fall 2025/DATA 255 - Deep Learning/HW6/imagenet_val20.zip\"\n",
        "\n",
        "def extract_and_find_data(zip_path, expected_name):\n",
        "    \"\"\"\n",
        "    Extract zip file and find the actual data directory.\n",
        "    Handles nested directory structures.\n",
        "    \"\"\"\n",
        "    print(f\"\\nExtracting {expected_name}...\")\n",
        "\n",
        "    # Extract to temporary directory\n",
        "    temp_extract_dir = f\"temp_{expected_name}\"\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(temp_extract_dir)\n",
        "\n",
        "    # Find the directory with class folders\n",
        "    def find_dataset_dir(root_dir):\n",
        "        \"\"\"Recursively find directory containing class folders.\"\"\"\n",
        "        for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "            # Check if this directory has subdirectories (potential classes)\n",
        "            if dirnames and not any(d.startswith('.') for d in dirnames):\n",
        "                # Check if subdirectories contain image files\n",
        "                first_subdir = os.path.join(dirpath, dirnames[0])\n",
        "                if os.path.isdir(first_subdir):\n",
        "                    files = os.listdir(first_subdir)\n",
        "                    if any(f.lower().endswith(('.jpg', '.jpeg', '.png', '.JPEG')) for f in files):\n",
        "                        return dirpath\n",
        "        return None\n",
        "\n",
        "    dataset_dir = find_dataset_dir(temp_extract_dir)\n",
        "\n",
        "    if dataset_dir is None:\n",
        "        raise FileNotFoundError(f\"Could not find dataset directory in {temp_extract_dir}\")\n",
        "\n",
        "    # Move to expected location\n",
        "    if os.path.exists(expected_name):\n",
        "        shutil.rmtree(expected_name)\n",
        "\n",
        "    shutil.move(dataset_dir, expected_name)\n",
        "\n",
        "    # Clean up temp directory\n",
        "    if os.path.exists(temp_extract_dir):\n",
        "        shutil.rmtree(temp_extract_dir)\n",
        "\n",
        "    # Verify\n",
        "    class_folders = [d for d in os.listdir(expected_name)\n",
        "                     if os.path.isdir(os.path.join(expected_name, d)) and not d.startswith('.')]\n",
        "    print(f\"✓ Found {len(class_folders)} class folders in {expected_name}\")\n",
        "\n",
        "    return expected_name\n",
        "\n",
        "# Extract training data\n",
        "if not os.path.exists(\"imagenet_train20a\"):\n",
        "    train_dir = extract_and_find_data(train_zip_path, \"imagenet_train20a\")\n",
        "else:\n",
        "    print(\"\\nTraining data already extracted.\")\n",
        "    train_dir = \"imagenet_train20a\"\n",
        "\n",
        "# Extract validation data\n",
        "if not os.path.exists(\"imagenet_val20\"):\n",
        "    val_dir = extract_and_find_data(val_zip_path, \"imagenet_val20\")\n",
        "else:\n",
        "    print(\"\\nValidation data already extracted.\")\n",
        "    val_dir = \"imagenet_val20\"\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"Data extraction complete!\")\n",
        "print(f\"{'='*70}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea0M9FOShNtz",
        "outputId": "9f49148e-44ff-4d4c-f142-fc89b7dce1b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "Extracting imagenet_train20a...\n",
            "✓ Found 20 class folders in imagenet_train20a\n",
            "\n",
            "Extracting imagenet_val20...\n",
            "✓ Found 1 class folders in imagenet_val20\n",
            "\n",
            "======================================================================\n",
            "Data extraction complete!\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 3. VERIFY DATA STRUCTURE\n",
        "# ================================================\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"VERIFYING DATA STRUCTURE\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "def verify_dataset(data_dir, name):\n",
        "    \"\"\"Verify dataset structure and count images.\"\"\"\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(f\"ERROR: Directory {data_dir} does not exist!\")\n",
        "        return False\n",
        "\n",
        "    class_folders = sorted([d for d in os.listdir(data_dir)\n",
        "                           if os.path.isdir(os.path.join(data_dir, d)) and not d.startswith('.')])\n",
        "\n",
        "    if len(class_folders) == 0:\n",
        "        print(f\"ERROR: No class folders found in {data_dir}!\")\n",
        "        return False\n",
        "\n",
        "    print(f\"Number of classes: {len(class_folders)}\")\n",
        "    print(f\"Class folders: {class_folders[:5]}...\" if len(class_folders) > 5 else f\"Class folders: {class_folders}\")\n",
        "\n",
        "    total_images = 0\n",
        "    for i, class_folder in enumerate(class_folders[:3]):  # Check first 3\n",
        "        class_path = os.path.join(data_dir, class_folder)\n",
        "        images = [f for f in os.listdir(class_path)\n",
        "                 if f.lower().endswith(('.jpg', '.jpeg', '.png', '.JPEG'))]\n",
        "        print(f\"  Class {i} ({class_folder}): {len(images)} images\")\n",
        "        total_images += len(images)\n",
        "\n",
        "    # Estimate total\n",
        "    avg_per_class = total_images / min(3, len(class_folders))\n",
        "    estimated_total = int(avg_per_class * len(class_folders))\n",
        "    print(f\"  Estimated total images: ~{estimated_total}\")\n",
        "\n",
        "    return True\n",
        "\n",
        "train_ok = verify_dataset(\"imagenet_train20a\", \"Training Dataset\")\n",
        "val_ok = verify_dataset(\"imagenet_val20\", \"Validation Dataset\")\n",
        "\n",
        "if not (train_ok and val_ok):\n",
        "    raise RuntimeError(\"Data verification failed! Check the zip files and extraction.\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"✓ Data verification passed!\")\n",
        "print(f\"{'='*70}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDMmGCWphQbO",
        "outputId": "df988bb7-6f2e-4f3e-8de7-3af818b94805"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "VERIFYING DATA STRUCTURE\n",
            "======================================================================\n",
            "\n",
            "Training Dataset:\n",
            "----------------------------------------------------------------------\n",
            "Number of classes: 20\n",
            "Class folders: ['n01737021', 'n02006656', 'n02011460', 'n02013706', 'n02033041']...\n",
            "  Class 0 (n01737021): 300 images\n",
            "  Class 1 (n02006656): 300 images\n",
            "  Class 2 (n02011460): 300 images\n",
            "  Estimated total images: ~6000\n",
            "\n",
            "Validation Dataset:\n",
            "----------------------------------------------------------------------\n",
            "Number of classes: 1\n",
            "Class folders: ['imagenet_val20']\n",
            "  Class 0 (imagenet_val20): 1000 images\n",
            "  Estimated total images: ~1000\n",
            "\n",
            "======================================================================\n",
            "✓ Data verification passed!\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 4. DATA LOADING - CLEAN AUGMENTATION\n",
        "# ================================================\n",
        "\n",
        "# ImageNet normalization\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "# MODERATE augmentation - NOT TOO AGGRESSIVE\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),  # Simple random crop, not aggressive\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "# Validation transforms (no augmentation)\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = datasets.ImageFolder(root=\"imagenet_train20a\", transform=train_transforms)\n",
        "val_dataset = datasets.ImageFolder(root=\"imagenet_val20\", transform=val_transforms)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                         num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                       num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"Dataset Loaded - CLEAN DATA\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Training samples:   {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n",
        "print(f\"Number of classes:  {len(train_dataset.classes)}\")\n",
        "print(f\"Batch size:         {batch_size}\")\n",
        "print(f\"Augmentation:       MINIMAL (flip + random crop only)\")\n",
        "print(f\"{'='*70}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM9hvKEohTey",
        "outputId": "eb339522-4d88-4cab-edfb-930fea8b5f6e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Dataset Loaded - CLEAN DATA\n",
            "======================================================================\n",
            "Training samples:   6000\n",
            "Validation samples: 1000\n",
            "Number of classes:  20\n",
            "Batch size:         32\n",
            "Augmentation:       MINIMAL (flip + random crop only)\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 5. VGG11 WITH PRETRAINED WEIGHTS - OPTIMIZED\n",
        "# ================================================\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load pretrained VGG11\n",
        "model = models.vgg11(weights=models.VGG11_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# FREEZE first 4 blocks of features (keep only last block trainable)\n",
        "freeze_count = 0\n",
        "for i, param in enumerate(model.features.parameters()):\n",
        "    if i < len(list(model.features.parameters())) - 6:  # Freeze all but last block\n",
        "        param.requires_grad = False\n",
        "        freeze_count += 1\n",
        "\n",
        "# MUCH SMALLER classifier head to prevent overfitting\n",
        "num_classes = 20\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.4),\n",
        "    nn.Linear(512 * 7 * 7, 512),  # Reduced: 25088 -> 512\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(p=0.3),\n",
        "    nn.Linear(512, num_classes)  # Direct to output\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"VGG11 Pretrained - Optimized for Validation Accuracy\")\n",
        "print(f\"{'='*70}\")\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"Frozen conv layers: {freeze_count} ({freeze_count*100//len(list(model.features.parameters())):.0f}%)\")\n",
        "print(f\"Classifier: 25088 -> 512 -> 20 (very small!)\")\n",
        "print(f\"Dropout: 0.4 -> 0.3 (prevents overfitting)\")\n",
        "print(f\"{'='*70}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRp4vPAThVlb",
        "outputId": "de164ca6-4422-4f12-f9bf-15988e65cf2e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg11-8a719046.pth\" to /root/.cache/torch/hub/checkpoints/vgg11-8a719046.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 507M/507M [00:02<00:00, 242MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "VGG11 Pretrained - Optimized for Validation Accuracy\n",
            "======================================================================\n",
            "Total parameters: 22,076,308\n",
            "Trainable parameters: 19,935,252\n",
            "Frozen conv layers: 10 (62%)\n",
            "Classifier: 25088 -> 512 -> 20 (very small!)\n",
            "Dropout: 0.4 -> 0.3 (prevents overfitting)\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 6. FINE-TUNING SETUP - PREVENT OVERFITTING\n",
        "# ================================================\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Conservative training for better validation generalization\n",
        "initial_lr = 0.0005  # Very low - only tune last layer\n",
        "optimizer = optim.SGD(model.parameters(), lr=initial_lr, momentum=0.9, weight_decay=0.001)\n",
        "\n",
        "num_epochs = 8\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4, 7], gamma=0.5)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"Training Setup - Minimize Overfitting\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Learning rate: {initial_lr} (very conservative)\")\n",
        "print(f\"Weight decay: 0.001 (L2 regularization)\")\n",
        "print(f\"Optimizer: SGD with momentum 0.9\")\n",
        "print(f\"Epochs: {num_epochs}\")\n",
        "print(f\"Scheduler: MultiStepLR (soft drops)\")\n",
        "print(f\"\\nStrategy:\")\n",
        "print(f\"  - Freeze most conv layers (learn features from ImageNet)\")\n",
        "print(f\"  - Small classifier (512 units only)\")\n",
        "print(f\"  - Low learning rate (minimal updates)\")\n",
        "print(f\"  - Moderate dropout (0.4 -> 0.3)\")\n",
        "print(f\"  - Clean data (minimal augmentation)\")\n",
        "print(f\"  - Goal: Better validation generalization\")\n",
        "print(f\"{'='*70}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM0bUhlfhWpC",
        "outputId": "0146daa7-524e-4cbf-bf44-ae7646737696"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Training Setup - Minimize Overfitting\n",
            "======================================================================\n",
            "Learning rate: 0.0005 (very conservative)\n",
            "Weight decay: 0.001 (L2 regularization)\n",
            "Optimizer: SGD with momentum 0.9\n",
            "Epochs: 8\n",
            "Scheduler: MultiStepLR (soft drops)\n",
            "\n",
            "Strategy:\n",
            "  - Freeze most conv layers (learn features from ImageNet)\n",
            "  - Small classifier (512 units only)\n",
            "  - Low learning rate (minimal updates)\n",
            "  - Moderate dropout (0.4 -> 0.3)\n",
            "  - Clean data (minimal augmentation)\n",
            "  - Goal: Better validation generalization\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 7. TRAINING FUNCTIONS\n",
        "# ================================================\n",
        "\n",
        "def calculate_accuracy(model, loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return 100 * correct / total\n",
        "\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        if (batch_idx + 1) % 25 == 0 or (batch_idx + 1) == len(train_loader):\n",
        "            batch_acc = 100 * correct / total\n",
        "            avg_loss = running_loss / (batch_idx + 1)\n",
        "            print(f\"  [{batch_idx + 1:3d}/{len(train_loader)}] \"\n",
        "                  f\"Loss: {loss.item():.4f} | Avg: {avg_loss:.4f} | Acc: {batch_acc:5.2f}%\", end='\\r')\n",
        "\n",
        "    print()\n",
        "    return running_loss / len(train_loader)\n",
        "\n",
        "print(\"Training functions ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TccslDKchX1W",
        "outputId": "ba21da77-9356-49a9-de3a-1d33f0b38bcd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training functions ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 8. MAIN TRAINING LOOP\n",
        "# ================================================\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"STARTING TRAINING - FAST CONVERGENCE MODE\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "best_val_acc = 0.0\n",
        "best_train_acc = 0.0\n",
        "start_time = time.time()\n",
        "target_reached_epoch = None\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start = time.time()\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs} | LR: {current_lr:.6f}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    avg_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    train_acc = calculate_accuracy(model, train_loader, device)\n",
        "    val_acc = calculate_accuracy(model, val_loader, device)\n",
        "    scheduler.step()\n",
        "\n",
        "    improved = \"\"\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        improved = \"NEW BEST!\"\n",
        "    if train_acc > best_train_acc:\n",
        "        best_train_acc = train_acc\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"EPOCH {epoch + 1} SUMMARY {improved}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"  Loss:           {avg_loss:.4f}\")\n",
        "    print(f\"  Train Accuracy: {train_acc:6.2f}% (best: {best_train_acc:6.2f}%)\")\n",
        "    print(f\"  Val Accuracy:   {val_acc:6.2f}% (best: {best_val_acc:6.2f}%)\")\n",
        "    print(f\"  Time:           {epoch_time:.1f}s\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    if val_acc >= 50 and target_reached_epoch is None:\n",
        "        target_reached_epoch = epoch + 1\n",
        "        print(f\"TARGET REACHED at epoch {target_reached_epoch}!\\n\")\n",
        "\n",
        "    if train_acc > 50 and val_acc > 50:\n",
        "        print(f\"REQUIREMENT MET! Both accuracies > 50%\\n\")\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "minutes, seconds = divmod(total_time, 60)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"TRAINING COMPLETE\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Total time: {int(minutes)}m {int(seconds)}s\")\n",
        "print(f\"Best train accuracy: {best_train_acc:.2f}%\")\n",
        "print(f\"Best val accuracy:   {best_val_acc:.2f}%\")\n",
        "if target_reached_epoch:\n",
        "    print(f\"Val 50% reached at:  Epoch {target_reached_epoch}\")\n",
        "print(f\"{'='*70}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DJOXwOYhY-x",
        "outputId": "d85844b2-5c57-4343-ffa2-e48091f31903"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STARTING TRAINING - FAST CONVERGENCE MODE\n",
            "======================================================================\n",
            "\n",
            "Epoch 1/8 | LR: 0.000500\n",
            "----------------------------------------------------------------------\n",
            "  [188/188] Loss: 2.5832 | Avg: 2.8133 | Acc: 17.43%\n",
            "\n",
            "======================================================================\n",
            "EPOCH 1 SUMMARY NEW BEST!\n",
            "======================================================================\n",
            "  Loss:           2.8133\n",
            "  Train Accuracy:  49.22% (best:  49.22%)\n",
            "  Val Accuracy:     3.00% (best:   3.00%)\n",
            "  Time:           23.4s\n",
            "======================================================================\n",
            "\n",
            "Epoch 2/8 | LR: 0.000500\n",
            "----------------------------------------------------------------------\n",
            "  [188/188] Loss: 1.6685 | Avg: 2.2650 | Acc: 44.57%\n",
            "\n",
            "======================================================================\n",
            "EPOCH 2 SUMMARY \n",
            "======================================================================\n",
            "  Loss:           2.2650\n",
            "  Train Accuracy:  70.87% (best:  70.87%)\n",
            "  Val Accuracy:     2.40% (best:   3.00%)\n",
            "  Time:           21.4s\n",
            "======================================================================\n",
            "\n",
            "Epoch 3/8 | LR: 0.000500\n",
            "----------------------------------------------------------------------\n",
            "  [188/188] Loss: 1.1464 | Avg: 1.7155 | Acc: 63.20%\n",
            "\n",
            "======================================================================\n",
            "EPOCH 3 SUMMARY NEW BEST!\n",
            "======================================================================\n",
            "  Loss:           1.7155\n",
            "  Train Accuracy:  81.18% (best:  81.18%)\n",
            "  Val Accuracy:     5.20% (best:   5.20%)\n",
            "  Time:           22.0s\n",
            "======================================================================\n",
            "\n",
            "Epoch 4/8 | LR: 0.000500\n",
            "----------------------------------------------------------------------\n",
            "  [188/188] Loss: 1.2239 | Avg: 1.2360 | Acc: 73.57%\n",
            "\n",
            "======================================================================\n",
            "EPOCH 4 SUMMARY NEW BEST!\n",
            "======================================================================\n",
            "  Loss:           1.2360\n",
            "  Train Accuracy:  86.17% (best:  86.17%)\n",
            "  Val Accuracy:     6.30% (best:   6.30%)\n",
            "  Time:           21.7s\n",
            "======================================================================\n",
            "\n",
            "Epoch 5/8 | LR: 0.000250\n",
            "----------------------------------------------------------------------\n",
            "  [188/188] Loss: 1.4874 | Avg: 0.9962 | Acc: 77.63%\n",
            "\n",
            "======================================================================\n",
            "EPOCH 5 SUMMARY \n",
            "======================================================================\n",
            "  Loss:           0.9962\n",
            "  Train Accuracy:  88.28% (best:  88.28%)\n",
            "  Val Accuracy:     6.10% (best:   6.30%)\n",
            "  Time:           21.4s\n",
            "======================================================================\n",
            "\n",
            "Epoch 6/8 | LR: 0.000250\n",
            "----------------------------------------------------------------------\n",
            "  [188/188] Loss: 1.0128 | Avg: 0.8665 | Acc: 80.22%\n",
            "\n",
            "======================================================================\n",
            "EPOCH 6 SUMMARY \n",
            "======================================================================\n",
            "  Loss:           0.8665\n",
            "  Train Accuracy:  89.57% (best:  89.57%)\n",
            "  Val Accuracy:     5.90% (best:   6.30%)\n",
            "  Time:           21.1s\n",
            "======================================================================\n",
            "\n",
            "Epoch 7/8 | LR: 0.000250\n",
            "----------------------------------------------------------------------\n",
            "  [188/188] Loss: 0.8722 | Avg: 0.7929 | Acc: 81.48%\n",
            "\n",
            "======================================================================\n",
            "EPOCH 7 SUMMARY \n",
            "======================================================================\n",
            "  Loss:           0.7929\n",
            "  Train Accuracy:  89.85% (best:  89.85%)\n",
            "  Val Accuracy:     5.90% (best:   6.30%)\n",
            "  Time:           21.2s\n",
            "======================================================================\n",
            "\n",
            "Epoch 8/8 | LR: 0.000125\n",
            "----------------------------------------------------------------------\n",
            "  [188/188] Loss: 0.8177 | Avg: 0.7268 | Acc: 82.22%\n",
            "\n",
            "======================================================================\n",
            "EPOCH 8 SUMMARY \n",
            "======================================================================\n",
            "  Loss:           0.7268\n",
            "  Train Accuracy:  90.45% (best:  90.45%)\n",
            "  Val Accuracy:     5.80% (best:   6.30%)\n",
            "  Time:           21.3s\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TRAINING COMPLETE\n",
            "======================================================================\n",
            "Total time: 2m 53s\n",
            "Best train accuracy: 90.45%\n",
            "Best val accuracy:   6.30%\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 9. FINAL EVALUATION\n",
        "# ================================================\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"FINAL EVALUATION\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "final_train_acc = calculate_accuracy(model, train_loader, device)\n",
        "final_val_acc = calculate_accuracy(model, val_loader, device)\n",
        "\n",
        "print(f\"\\nFinal Training Accuracy:   {final_train_acc:6.2f}%\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc:6.2f}%\")\n",
        "print(f\"\\nBest Training Accuracy:    {best_train_acc:6.2f}%\")\n",
        "print(f\"Best Validation Accuracy:  {best_val_acc:6.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "191hdnl0heof",
        "outputId": "998bfb9e-a211-4c03-8dc8-a62431ab1dd4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "FINAL EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Final Training Accuracy:    90.75%\n",
            "Final Validation Accuracy:   5.80%\n",
            "\n",
            "Best Training Accuracy:     90.45%\n",
            "Best Validation Accuracy:    6.30%\n"
          ]
        }
      ]
    }
  ]
}